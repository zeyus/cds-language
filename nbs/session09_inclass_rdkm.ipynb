{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AXHLDxJdRzBi"
      },
      "source": [
        "# Session 9 - Using Bert-style models for Cultural Data Science\n",
        "\n",
        "[*NB: This notebook is taken directly from the documentation for the package ```BERTopic``` which we're working with today. You can find more at the website [here](https://maartengr.github.io/BERTopic/index.html) and at the [Github repo](https://github.com/MaartenGr/BERTopic)*]\n",
        "\n",
        "In this tutorial we will be exploring how to use BERTopic to create topics from the well-known [20Newsgroups dataset](http://qwone.com/~jason/20Newsgroups/). The most frequent use-cases and methods are discussed together with important parameters to keep a look out for. \n",
        "\n",
        "\n",
        "## BERTopic\n",
        "BERTopic is a topic modeling technique that leverages ðŸ¤— transformers and a custom class-based TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions. \n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png\" width=\"40%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3VGFZ1USMTu"
      },
      "source": [
        "# Data\n",
        "For this example, we use the popular 20 Newsgroups dataset which contains roughly 18000 newsgroups posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJij3WP6SEQD"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "docs = fetch_20newsgroups(subset='all',  \n",
        "                          remove=('headers', 'footers', 'quotes'))['data']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also try to instead make use of a smaller dataset, like the fake vs real news data we've worked with previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "filename = os.path.join()\n",
        "# using only the titles\n",
        "docs = pd.read_csv(filename)[\"title\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBcNmZJzSTY8"
      },
      "source": [
        "# **Topic Modeling**\n",
        "\n",
        "In this example, we will go through the main components of BERTopic and the steps necessary to create a strong topic model. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI6vwelqnTL-"
      },
      "source": [
        "## Training\n",
        "\n",
        "We start by instantiating BERTopic. We set language to `english` since our documents are in the English language. If you would like to use a multi-lingual model, please use `language=\"multilingual\"` instead. \n",
        "\n",
        "We will also calculate the topic probabilities. However, this can slow down BERTopic significantly at large amounts of data (>100_000 documents). It is advised to turn this off if you want to speed up the model. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfhfzqkoSJ1I"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# initialize the model\n",
        "topic_model = BERTopic(language=\"english\", \n",
        "                       calculate_probabilities=True, \n",
        "                       verbose=True)\n",
        "\n",
        "# notice how we use the same fit_transform logic as we've seen before\n",
        "topics, probs = topic_model.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJs94tXDo4f6"
      },
      "source": [
        "**NOTE**: Use `language=\"multilingual\"` to select a model that support 50+ languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5O3KpHTnVpz"
      },
      "source": [
        "## Extracting Topics\n",
        "After fitting our model, we can start by looking at the results. Typically, we look at the most frequent topics first as they best represent the collection of documents. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ScBUgXn06IK6",
        "outputId": "ee49a346-8d12-41c4-c7e9-8c1b6782c636"
      },
      "outputs": [],
      "source": [
        "freq = topic_model.get_topic_info()\n",
        "freq.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BtOgifV7Q-H"
      },
      "source": [
        "-1 refers to all outliers and should typically be ignored. Next, let's take a look at a frequent topic that were generated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVpvT4bA6KiN",
        "outputId": "9cf99b89-30bb-45fe-b98b-063f8f3624d9"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic(0)  # Select the most frequent topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixc-X2JzodrZ"
      },
      "source": [
        "**NOTE**: BERTopic is stocastich which mmeans that the topics might differ across runs. This is mostly due to the stocastisch nature of UMAP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j91cP3xBpWDM"
      },
      "source": [
        "## Attributes\n",
        "\n",
        "There are a number of attributes that you can access after having trained your BERTopic model:\n",
        "\n",
        "\n",
        "| Attribute | Description |\n",
        "|------------------------|---------------------------------------------------------------------------------------------|\n",
        "| topics_               | The topics that are generated for each document after training or updating the topic model. |\n",
        "| probabilities_ | The probabilities that are generated for each document if HDBSCAN is used. |\n",
        "| topic_sizes_           | The size of each topic                                                                      |\n",
        "| topic_mapper_          | A class for tracking topics and their mappings anytime they are merged/reduced.             |\n",
        "| topic_representations_ | The top *n* terms per topic and their respective c-TF-IDF values.                             |\n",
        "| c_tf_idf_              | The topic-term matrix as calculated through c-TF-IDF.                                       |\n",
        "| topic_labels_          | The default labels for each topic.                                                          |\n",
        "| custom_labels_         | Custom labels for each topic as generated through `.set_topic_labels`.                                                               |\n",
        "| topic_embeddings_      | The embeddings for each topic if `embedding_model` was used.                                                              |\n",
        "| representative_docs_   | The representative documents for each topic if HDBSCAN is used.                                                |\n",
        "\n",
        "For example, to access the predicted topics for the first 10 documents, we simply run the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCMHaWVMpbo3"
      },
      "outputs": [],
      "source": [
        "topic_model.topics_[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbT2Bd9gqaJ3"
      },
      "source": [
        "# **Visualization**\n",
        "There are several visualization options available in BERTopic, namely the visualization of topics, probabilities and topics over time. Topic modeling is, to a certain extent, quite subjective. Visualizations help understand the topics that were created. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8c8LenB8Zyl"
      },
      "source": [
        "## Visualize Topics\n",
        "After having trained our `BERTopic` model, we can iteratively go through perhaps a hundred topic to get a good \n",
        "understanding of the topics that were extract. However, that takes quite some time and lacks a global representation. \n",
        "Instead, we can visualize the topics that were generated in a way very similar to \n",
        "[LDAvis](https://github.com/cpsievert/LDAvis):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "S9qDqEHddgKq",
        "outputId": "3fddd5f1-194e-4708-a7dc-f0c5602c140a"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITB7bf6q8nWQ"
      },
      "source": [
        "## Visualize Topic Probabilities\n",
        "\n",
        "The variable `probabilities` that is returned from `transform()` or `fit_transform()` can \n",
        "be used to understand how confident BERTopic is that certain topics can be found in a document. \n",
        "\n",
        "To visualize the distributions, we simply call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ypfI1-KHdmcX",
        "outputId": "4fd56127-4143-4cf7-d227-ef43725f1ad7"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_distribution(probs[200], min_probability=0.015)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHRTeSpl5JYB"
      },
      "source": [
        "## Visualize Topic Hierarchy\n",
        "\n",
        "The topics that were created can be hierarchically reduced. In order to understand the potential hierarchical structure of the topics, we can use scipy.cluster.hierarchy to create clusters and visualize how they relate to one another. This might help selecting an appropriate nr_topics when reducing the number of topics that you have created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "ltmLFRR56a4X",
        "outputId": "0458e59c-30ce-4700-8dbf-0932afc63f1d"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_hierarchy(top_n_topics=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4spXl2_C6flq"
      },
      "source": [
        "## Visualize Terms\n",
        "\n",
        "We can visualize the selected terms for a few topics by creating bar charts out of the c-TF-IDF scores for each topic representation. Insights can be gained from the relative c-TF-IDF scores between and within topics. Moreover, you can easily compare topic representations to each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "zpm9LsKW6mi5",
        "outputId": "1197affc-dde2-44c1-9ba7-c9fb36a1143c"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_barchart(top_n_topics=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCPdi6_z6sbT"
      },
      "source": [
        "## Visualize Topic Similarity\n",
        "Having generated topic embeddings, through both c-TF-IDF and embeddings, we can create a similarity matrix by simply applying cosine similarities through those topic embeddings. The result will be a matrix indicating how similar certain topics are to each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "edzNhZuZ6wTr",
        "outputId": "e01231db-fe82-49d3-a96f-8135522d9b9b"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_heatmap(n_clusters=20, \n",
        "                              width=1000, \n",
        "                              height=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ak_CLR164mx"
      },
      "source": [
        "## Visualize Term Score Decline\n",
        "Topics are represented by a number of words starting with the best representative word. Each word is represented by a c-TF-IDF score. The higher the score, the more representative a word to the topic is. Since the topic words are sorted by their c-TF-IDF score, the scores slowly decline with each word that is added. At some point adding words to the topic representation only marginally increases the total c-TF-IDF score and would not be beneficial for its representation.\n",
        "\n",
        "To visualize this effect, we can plot the c-TF-IDF scores for each topic by the term rank of each word. In other words, the position of the words (term rank), where the words with the highest c-TF-IDF score will have a rank of 1, will be put on the x-axis. Whereas the y-axis will be populated by the c-TF-IDF scores. The result is a visualization that shows you the decline of c-TF-IDF score when adding words to the topic representation. It allows you, using the elbow method, the select the best number of words in a topic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "7gT3Korh6-MX",
        "outputId": "5810f810-4633-425e-a7d2-3a1e9570639a"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_term_rank()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D48ienfZrfP0"
      },
      "source": [
        "# **Topic Representation**\n",
        "After having created the topic model, you might not be satisfied with some of the parameters you have chosen. Fortunately, BERTopic allows you to update the topics after they have been created. \n",
        "\n",
        "This allows for fine-tuning the model to your specifications and wishes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4m3UMsw-Zxk"
      },
      "source": [
        "## Update Topics\n",
        "When you have trained a model and viewed the topics and the words that represent them,\n",
        "you might not be satisfied with the representation. Perhaps you forgot to remove\n",
        "stopwords or you want to try out a different `n_gram_range`. We can use the function `update_topics` to update \n",
        "the topic representation with new parameters for `c-TF-IDF`: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWm7B-FJ-iYW"
      },
      "outputs": [],
      "source": [
        "topic_model.update_topics(docs, \n",
        "                          n_gram_range=(1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf31gQavdtfG",
        "outputId": "b2cf3d47-f665-44fe-bbe0-c927e4d73363"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic(0)   # We select topic that we viewed before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9antKpdC91A-"
      },
      "source": [
        "## Topic Reduction\n",
        "We can also reduce the number of topics after having trained a BERTopic model. The advantage of doing so, \n",
        "is that you can decide the number of topics after knowing how many are actually created. It is difficult to \n",
        "predict before training your model how many topics that are in your documents and how many will be extracted. \n",
        "Instead, we can decide afterwards how many topics seems realistic:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m4Nd7Us-Peg",
        "outputId": "2d442d39-5bc5-4e7f-c155-6e6c664f6714"
      },
      "outputs": [],
      "source": [
        "topic_model.reduce_topics(docs, nr_topics=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVAYd7pXJ1_T",
        "outputId": "433d5607-cf1d-421d-9bee-070363f13abb"
      },
      "outputs": [],
      "source": [
        "# Access the newly updated topics with:\n",
        "print(topic_model.topics_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipzieuf2J4rr"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXYJ745O-03Z"
      },
      "source": [
        "# **Search Topics**\n",
        "After having trained our model, we can use `find_topics` to search for topics that are similar \n",
        "to an input search_term. Here, we are going to be searching for topics that closely relate the \n",
        "search term \"vehicle\". Then, we extract the most similar topic and check the results: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAdiVYej-2i-",
        "outputId": "c107bd7d-1025-4d4d-b179-d007c7d16cd2"
      },
      "outputs": [],
      "source": [
        "similar_topics, similarity = topic_model.find_topics(\"vehicle\", top_n=5)\n",
        "print(similar_topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9paNa09d3Xy",
        "outputId": "545bbd07-8850-46d4-fdb7-28cb3d158b15"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic(71)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wekNoQNuUVoU"
      },
      "source": [
        "# **Model serialization**\n",
        "The model and its internal settings can easily be saved. Note that the documents and embeddings will not be saved. However, UMAP and HDBSCAN will be saved. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWUF1uxiSb_a"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "topic_model.save(\"my_model\")\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_eHBI1jSb6i"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "my_model = BERTopic.load(\"my_model\")\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eyImbal7lb8"
      },
      "source": [
        "# **Embedding Models**\n",
        "The parameter `embedding_model` takes in a string pointing to a sentence-transformers model, a SentenceTransformer, or a Flair DocumentEmbedding model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZKyW7NZpnEk"
      },
      "source": [
        "## Sentence-Transformers\n",
        "You can select any model from sentence-transformers here and pass it through BERTopic with embedding_model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7sPgNfzprbP"
      },
      "outputs": [],
      "source": [
        "topic_model = BERTopic(embedding_model=\"xlm-r-bert-base-nli-stsb-mean-tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vv7i1JTp62V"
      },
      "source": [
        "Or select a SentenceTransformer model with your own parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh5qp58Hp7Ua"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "sentence_model = SentenceTransformer(\"distilbert-base-nli-mean-tokens\", device=\"cpu\")\n",
        "topic_model = BERTopic(embedding_model=sentence_model, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoMc1W-x7-b5"
      },
      "source": [
        "Click [here](https://www.sbert.net/docs/pretrained_models.html) for a list of supported sentence transformers models.  \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
